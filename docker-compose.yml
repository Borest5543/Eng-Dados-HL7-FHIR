
services:
  # ==========================================
  # ðŸ—„ï¸ PostgreSQL
  # ==========================================
  postgres:
    image: postgres:15
    container_name: fhir_postgres_2
    environment:
      POSTGRES_DB: fhir
      POSTGRES_USER: fhir_user
      POSTGRES_PASSWORD: fhir_pass
      TZ: America/Sao_Paulo
      LANG: en_US.UTF-8
      LC_ALL: en_US.UTF-8
    ports:
      - "5111:5432"
    volumes:
      - pgdata_fhir:/var/lib/postgresql/data
      - ./init-db:/docker-entrypoint-initdb.d
    networks:
      - fhir_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U fhir_user -d fhir"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ==========================================
  # ðŸ¥ HAPI FHIR Server com PostgreSQL
  # ==========================================
  fhir-server:
    image: hapiproject/hapi:latest
    container_name: hapi_fhir_2
    restart: always
    ports:
      - "8583:8080"
    environment:
      TZ: America/Sao_Paulo
      LANG: pt_BR.UTF-8
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/fhir
      SPRING_DATASOURCE_USERNAME: fhir_user
      SPRING_DATASOURCE_PASSWORD: fhir_pass
      SPRING_DATASOURCE_DRIVERCLASSNAME: org.postgresql.Driver
      SPRING_JPA_HIBERNATE_DDL_AUTO: create
      SPRING_JPA_PROPERTIES_HIBERNATE_DIALECT: ca.uhn.fhir.jpa.model.dialect.HapiFhirPostgresDialect

    depends_on:
      postgres:
        condition: service_healthy

    networks:
      - fhir_network
    volumes:
      - fhir_logs:/usr/local/tomcat/logs



  # ===============================
  # ðŸš€ Airflow (Python + Spark)
  # ===============================
  airflow:
    build: .
    container_name: airflow_2
    restart: always
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://fhir_user:fhir_pass@postgres:5432/airflow
      AIRFLOW__CORE__LOAD_EXAMPLES: "False"
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
      JAVA_HOME: /usr/lib/jvm/java-17-openjdk-amd64
      SPARK_HOME: /opt/spark
    volumes:
      - ./entrypoint-airflow.sh:/entrypoint-airflow.sh
      - ./dags:/opt/airflow/dags
      - ./data:/opt/data
      - ./spark_app:/opt/spark_app
    ports:
      - "8581:8080"
    depends_on:
      - postgres
      - spark-master
      - kafka
    command: >
      bash -c "
        chmod +x /entrypoint-airflow.sh;
        /entrypoint-airflow.sh
      "
    networks:
      - fhir_network

  # ===============================
  # âš¡ Spark (Master + Worker)
  # ===============================
  spark-master:
    build: .
    container_name: spark-master_2
    restart: always
    environment:
      JAVA_HOME: /usr/lib/jvm/java-17-openjdk-amd64
      SPARK_HOME: /opt/spark
      SPARK_MODE: master
    command: >
      bash -c "
        echo 'ðŸš€ Iniciando Spark Master...';
        mkdir -p /opt/spark/logs;
        /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master \
          --host spark-master --port 7077 --webui-port 8085 \
          >> /opt/spark/logs/master.log 2>&1 &
        tail -f /opt/spark/logs/*.log
      "
    ports:
      - "7077:7077"
      - "8085:8085"
    volumes:
      - ./spark_app:/opt/spark_app
      - ./data:/opt/data
    networks:
      - fhir_network

  spark-worker:
    build: .
    container_name: spark-worker_2
    restart: always
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
    command: ["/opt/spark/bin/spark-class", "org.apache.spark.deploy.worker.Worker", "spark://spark-master:7077", "--cores", "2", "--memory", "2G", "--webui-port", "8086"]
    ports:
      - "8086:8086"
    volumes:
      - ./spark_app:/opt/spark_app
      - ./data:/opt/data
    networks:
      - fhir_network



  # ===============================
  # ðŸ¦œ Kafka (mensageria HL7/FHIR)
  # ===============================
  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.0
    container_name: zookeeper_2
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    networks:
      - fhir_network

  kafka:
    image: confluentinc/cp-kafka:7.6.0
    container_name: kafka_2
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    volumes:
      - kafka_data:/var/lib/kafka/data
    networks:
      - fhir_network

# ===============================
# ðŸ“¦ Volumes e Rede
# ===============================
volumes:
  pgdata_fhir:
  kafka_data:
  fhir_logs:

networks:
  fhir_network:
    driver: bridge
